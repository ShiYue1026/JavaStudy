# 引论

## 什么是操作系统？

操作系统是计算机系统中管理硬件和软件资源的中间层系统，屏蔽了硬件的复杂性，并且为用户提供了便捷的交互方式

![三分恶面渣逆袭：操作系统是什么](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-be55aec1-e7ab-433f-97f1-14d99960b6bf.png)



## 操作系统主要有哪些功能

![ 三分恶面渣逆袭：操作系统主要功能](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-eee82952-c96f-45c9-835e-29db37c0f6d8.png)

- 负责创建和终止进程
- 负责为进程分配资源
- 提供创建、删除、读写文件的功能，并组织文件的存储结构，比如说目录
- 通过设备驱动程序控制和管理计算机的硬件设备，如鼠标、键盘、打印机等



# 操作系统结构

## 什么是内核

内核是一个计算机程序，它是操作系统的核心，提供了操作系统最核心的能力，可以控制操作系统中所有的内容，如进程管理、内存管理、文件系统管理、设备管理等。



## 什么是用户态和内核态

在计算机系统中，内存可分为两大区域：**内核空间**和**用户空间**。这种划分主要用户保护系统的稳定性和安全性。

![二哥的 Java 进阶之路：用户空间和内核空间](https://cdn.tobebetterjavaer.com/stutymore/os-20240724170451.png)

- 内核空间
  - 操作系统内核代码及其运行时数据结构所在的内存区域，拥有对系统所有资源的完全访问权限，如进程管理、内存管理、文件系统、网络堆栈等。
- 用户空间
  - 是操作系统为应用程序（如用户运行进程）分配的内存区域，用户空间中的进程不能直接访问硬件或内核数据结构



## 微内核和宏内核是什么

宏内核

- 一体化，所有核心模块都在内核中
- 性能高，因为内核内部调用很快
- 模块隔离性弱，一个模块崩溃可能影响整个系统
- 扩展性弱



微内核

- 极简主义，只保留最基本功能
- 性能相对较低，因涉及用户态↔内核态频繁通信
- 模块隔离性强，模块在用户态，崩溃不会拖垮内核
- 扩展性好，功能模块可单独替换/重启



## 用户态和内核态是如何切换的

当应用程序执行系统调用时，CPU 将从用户态切换到内核态，进入内核空间执行相应的内核代码，然后再切换回用户态。

![三分恶面渣逆袭：用户态&内核态切换](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-b358cdae-18b6-45d4-8a5b-4ea3a7cfc273.png)

系统调用是应用程序请求操作系统内核提供服务的接口，如文件操作（如 open、read、write）、进程控制（如 fork、exec）、内存管理（如 mmap）等。



## 中断向量表是什么

当 CPU 发生中断或异常时（比如键盘输入、定时器响起、除零错误等）：

1. CPU 自动查表：从中断向量表中找到对应中断号的处理函数地址
2. 切换到内核态，保存当前现场
3. 跳转执行中断处理函数
4. 处理完成后返回，恢复用户程序继续执行



## 软中断和硬件中断是什么

软中断：由软件程序触发，例如系统调用，软中断不依赖外部设备，而是**由指令触发**。

硬件中断：由外部设备（如键盘、鼠标、磁盘）触发，通常用于让 CPU 处理外部事件，如键盘输入、鼠标点击、网络数据到达等。



# 进程和线程

## 并行和并发有什么区别

![并发和并行](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-fb7891d8-8330-494b-9bc1-cf829b5cc82d.png)

并发就是在一段时间内，多个任务都会被处理；**但在某一时刻，只有一个任务在执行。**

- 单核处理器做到的并发，其实是利用时间片的轮转，例如有两个进程 A 和 B，A 运行一个时间片之后，切换到 B，B 运行一个时间片之后又切换到 A。因为切换速度足够快，所以宏观上表现为在一段时间内能同时运行多个程序。



并行就是在同一时刻，有多个任务在执行。

- 这需要多核处理器才能完成，在微观上就能同时执行多条指令，不同的程序被放到不同的处理器上运行这个是物理上的多个进程同时执行。



## 什么是进程上下文切换

![三分恶面渣逆袭：进程上下文切换](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-187d1cf9-971d-4395-b888-5e6eaf2be5f1.png)

上下文切换是操作系统在多任务处理环境中，将CPU从一个进程切换到另一个进程的过程。通过让多个进程共享CPU资源，使系统能够并发执行多个任务。

进程上下文切换包含以下几个步骤：

- 保存当前进程的上下文
  - 操作系统保存当前进程的CPU寄存器，程序状态等关键信息

- 选择下一个进程
  - 调度程序选择下一个要执行的进程
- 恢复上一个进程的上下文
- 切换到下一个进程



进程的上下文切换不仅包含了**虚拟内存、栈、全局变量**等用户空间的资源，还包括了**内核堆栈、寄存器等**内核空间的资源。

通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示：

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/e506e0c6accf01a2e93bfb484e754d5b.png)





## 进程有哪些状态

![进程5种状态](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-ae17a9dc-f555-481a-ba4a-caca06120be7.png)

- 新建状态（New）：进程正在被创建时的状态
- 终止状态（Exit）：进程正在从系统中消失时的状态
- 运行状态（*Runing*）：该时刻进程占用CPU；
- 就绪状态（*Ready*）：可运行，由于其他进程处于运行状态而暂时停⽌运行；
- 阻塞状态（*Blocked*）：该进程正在等待某⼀事件发生（如等待输⼊/输出操作的完成）而暂时停止运行，这时，即使给它 CPU 控制权，它也无法运行；



## 什么是僵尸进程

僵尸进程是已完成且处于终止状态，但在进程表中仍然存在的进程。



**为什么会有僵尸进程**

- 父进程没有调用 `wait()`
  - 如果父进程没有调用 `wait()` 或 `waitpid()`，操作系统不会从进程表中移除子进程的信息，导致子进程变成**僵尸进程**。

- 父进程还在运行，但没有管理子进程
  - 父进程可能**忘记回收子进程**，但它自己仍然在运行，导致子进程进入僵尸状态。



## 什么是孤儿进程

一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。

孤儿进程将被 init 进程 (进程 ID 为 1 的进程) 所收养，并由 init 进程对它们完成状态收集工作。因为孤儿进程会被 init 进程收养，所以孤儿进程不会对系统造成危害。



## 什么是僵尸进程

当子进程先退出，但父进程没有调用 `wait()` 回收它，子进程变成僵尸进程。

僵尸进程不会占用 CPU 和内存，但它仍然占据进程表，如果积累过多，可能导致系统崩溃（进程表耗尽）。



## 进程有哪些调度算法

进程调度是操作系统中的核心功能，负责决定哪些进程在何时使用CPU。

**1. 先来先服务**

进程按照请求CPU的顺序进行调度。易于实现，但可能会导致较短的进程等待较长进程执行完成，从而产生“饥饿”现象

![三分恶面渣逆袭：先来先服务](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-93088d03-80c9-46c5-9eaf-eead2adb6e12.png)

**2. 短作业优先**

选择预计运行时间最短的进程优先执行。这种方式可以减少平均等待时间和响应时间，但缺点是很难准确预知进程的执行时间，并且可能因为一直有短作业在执行导致长作业持续被推迟。

![三分恶面渣逆袭：短作业优先](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-517e8392-64fe-4de3-9e1c-b3a944822aba.png)

**3. 优先级调度**

每个进程被分配一个优先级。CPU首先分配给优先级最高的进程。

优先级调度可以是非抢占式的或抢占式的。在非抢占式优先级调度中，进程一旦开始执行将一直运行直到完成；在抢占式优先级调度中，更高优先级的进程可以中断正在执行的低优先级进程。

![三分恶面渣逆袭：优先级调度](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-7c4441cf-7b8c-4660-8ba8-29b8076e2da1.png)

**4. 时间片轮转**

时间片轮转调度为每个进程分配一个固定的时间段，称为时间片，进程可以在这个时间片内运行。如果进程在时间片结束时还没有完成，它将被放回队列的末尾。时间片轮转是公平的调度方式，可以保证所有进程得到公平的 CPU 时间，适用于共享系统。

![三分恶面渣逆袭：时间片轮转](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-ad224c3a-8ac9-4230-84e4-ec434d5b49f9.png)

**5. 最短剩余时间优先**

这是短作业优先的一种改进形式，它是抢占式的。即如果一个新进程的预计执行时间比当前运行进程的剩余时间短，调度器将暂停当前的进程，并切换到新进程。这种方法也可以最小化平均等待时间，但同样面临预测执行时间的困难。

**6. 多级反馈队列**

一个进程需要执行100 个时间片，如果采用时间片轮转调度算法，那么需要交互 100 次。

多级队列就是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列的时间片大小不同，比如 2,4,6,8······。进程在第一个队列没执行完，就会被移到下一个队列。

这种方式下，之前的进程只需要交换 7 次就可以了。每个队列优先权不一样，最上面的队列优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

![DIDA-lJ-多级反馈队列](https://cdn.tobebetterjavaer.com/stutymore/os-20240426094524.png)



## 进程间通信有哪些方式

![编程十万问：进程间通信](https://cdn.tobebetterjavaer.com/stutymore/os-20240314073226.png)

**1. 管道**

- 管道可以理解成不同进程之间的传话筒，一方发声，一方接收

- **进程间的管道就是内核中的一串缓存**，从管道的一端写入数据，另一端读取。数据只能单向流动，遵循先进先出（FIFO）的原则。

- 缺点：管道的效率低，不适合进程间频繁地交换数据。

  - 需要内核态和用户态的切换
  - 调用 `write(fd, data, size)`写入内核缓冲区
  - 调用 `read(fd, buffer, size)`从内核缓冲区读取
  
  ![编程十万问：管道](https://cdn.tobebetterjavaer.com/stutymore/os-20240314073535.png)

**2. 信号**

- 用于通知接收进程某件事情发生了，是一种较为简单的通信方式，主要用于处理异步事件。当进程收到信号时，内核会打断当前任务，执行信号处理函数。
- 常用信号
  - SIGHUP：当我们退出终端（Terminal）时，由该终端启动的所有进程都会接收到这个信号，默认动作为终止进程。
  - SIGINT：程序终止（interrupt）信号。按 `Ctrl+C` 时发出，大家应该在操作终端时有过这种操作。
  - SIGQUIT：和 SIGINT 类似，按 `Ctrl+\` 键将发出该信号。它会产生核心转储文件，将内存映像和程序运行时的状态记录下来。
  - SIGKILL：强制杀死进程，本信号不能被阻塞和忽略。
  - SIGTERM：与 SIGKILL 不同的是该信号可以被阻塞和处理。通常用来要求程序自己正常退出。

**3. 消息队列**

- 消息队列是保存在内核中的消息链表，按照消息的类型进行消息传递，具有较高的可靠性和稳定性。

- 缺点：消息体有一个最大长度的限制，不适合比较大的数据传输；存在用户态与内核态之间的数据拷贝开销。

  ![编程十万问：消息队列](https://cdn.tobebetterjavaer.com/stutymore/os-20240314075045.png)

**4. 共享内存**

- 允许两个或多个进程共享一个给定的内存区，一个进程写入的东西，其他进程马上就能看到。

- 共享内存是最快的进程间通信方式，它是针对其他进程间通信方式运行效率低而专门设计的。

- 缺点：当多进程竞争同一个共享资源时，会造成数据错乱的问题。

  ![三分恶面渣逆袭：共享内存](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-d9e3cfaf-01e7-42ff-9290-94ef4a5c7d5e.png)

**5. 信号量**

- 信号量可以理解成红绿灯，红灯停（信号量为零），绿灯行（信号量非零）。**它本质上是一个计数器**，用来控制对共享资源的访问数量。

  ![三分恶面渣逆袭：信号量](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-5fb765af-918c-4037-a3ad-4cad4d985e16.png)

**6. 套接字**

- 提供网络通信的端点，可以让不同机器上运行的进程之间进行双向通信。

![img](https://cdn.tobebetterjavaer.com/stutymore/os-20240314082438.png)



## 进程和线程的联系和区别

- 进程是一个正在执行的程序实例。每个进程都有自己独立的地址空间、全局变量、堆栈、和文件描述符等资源。

- 线程是进程中的一个执行单元。一个进程可以包含多个线程，它们共享进程的地址空间和资源。

- 进程切换需要保存和恢复大量的上下文信息，代价较高。线程切换相对较轻量，因为线程共享进程的地址空间，**只需要保存和恢复线程私有的数据。**
- 线程的生命周期由进程控制，进程终止时，其所有线程也会终止。

| 特性       | 进程                         | 线程                             |
| ---------- | ---------------------------- | -------------------------------- |
| 地址空间   | 独立                         | 共享                             |
| 内存开销   | 高                           | 低                               |
| 上下文切换 | 慢，开销大                   | 快，开销小                       |
| 通信       | 需要 IPC 机制，开销较大      | 共享内存，直接通信               |
| 创建销毁   | 开销大，较慢                 | 开销小，较快                     |
| 并发性     | 低                           | 高                               |
| 崩溃影响   | 一个进程崩溃不会影响其他进程 | 一个线程崩溃可能导致整个进程崩溃 |



## 进程、线程、协程区别

协程是一种用户态的轻量级线程，由程序自身调度（非操作系统内核），避免线程上下文切换。

多个协程在 **一个线程内执行**，**不会触发线程切换**，避免 CPU 资源浪费。



## 线程共享和不共享进程哪些资源

共享：

- 进程代码段
- 进程数据段（全局变量和静态变量）
- 进程打开的文件描述符
- 进程内存空间（堆和数据段）



不共享：

- 寄存器
- 栈



## 线程间通信方式





## 线程上下文切换了解吗

- 当两个线程不是属于同⼀个进程，则切换的过程就跟进程上下文切换⼀样；
- 当两个线程属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据

所以，线程的上下文切换相比进程开销要小很多



## 线程有哪些实现方式

**1. 内核态线程实现**

- 在内核空间实现的线程，由内核直接管理直接管理线程

  ![内核态线程实现](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-30b84285-8027-4720-b50b-3b0fb18c756f.png)

**2. 用户态线程实现**

- 在用户空间实现线程，不需要内核的参与，内核对线程无感知

  ![用户态线程](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-57886181-56fe-42bf-85e1-4d062455788a.png)

**3.混合线程实现**

- 现代操作系统基本都是将两种方式结合起来使用。用户态的执行系统负责进程内部线程在非阻塞时的切换；内核态的操作系统负责阻塞线程的切换。

- 多个用户级线程（N）映射到多个内核级线程（M），即 N:M 线程调度。

  ![混合线程实现](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-1597d159-1b07-48ae-ac86-7e9b9cb85876.png)



## 用户态线程和内核态线程有什么区别

**用户级线程（ULT）**：

- **优点**：上下文切换快，不需要用户态/内核态切换。
- **缺点**：不能利用多核 CPU，且如果一个线程阻塞，整个进程都会被挂起。

**内核级线程（KLT）**：

- **优点**：支持多核 CPU 并行执行，线程阻塞不影响其他线程。
- **缺点**：线程切换涉及内核态，**开销大**（寄存器切换、TLB 刷新）。



## 线程间如何同步

同步解决的是多线程操作共享资源的问题，不管线程之间是如何穿插执行的，最后的结果都是正确的。

![cxuan：使用临界区的互斥](https://cdn.tobebetterjavaer.com/stutymore/javathread-20241008102844.png)

**临界区**：对共享资源访问的程序片段，我们希望这段代码是`互斥`的，可以保证在某个时刻只能被一个线程执行，也就是说一个线程在临界区执行时，其它线程应该被阻止进入临界区。



**1. 互斥锁**:

- 使用加锁操作和解锁操作可以解决并发线程/进程的互斥问题。
- 任何想进⼊临界区的线程，必须先执行加锁操作。若加锁操作顺利通过，则线程可进入临界区；在完成对临界资源的访问后再执行解锁操作，以释放该临界资源。
- 根据锁的实现不同，可以分为`忙等待锁`和`⽆忙等待锁`。
  - 忙等待锁（也称为自旋锁，Spinlock）是指当一个线程试图获取锁时，如果该锁已经被其他线程持有，当前线程不会立即进入休眠或阻塞，而是不断地检查锁的状态，直到该锁可用为止。
    - 优点是避免了线程的上下文切换
    - 缺点是浪费CPU资源
  - 无忙等待锁是指当一个线程尝试获取锁时，如果锁已经被其他线程持有，当前线程不会忙等待，而是主动让出 CPU，进入阻塞状态或休眠状态，等待锁释放
  - 当锁被释放时，线程被唤醒并重新尝试获取锁。

**2. 信号量**

信号量是操作系统提供的⼀种协调共享资源访问的方法。**通常表示资源的数量**，对应的变量是⼀个整型（sem）变量。

另外，还有两个原子操作的系统调用函数来控制信号量，分别是：

- *P* 操作：当线程想要进入临界区时，会尝试执行 P 操作。如果信号量的值大于 0，信号量值减 1，线程可以进入临界区；否则，线程会被阻塞，直到信号量大于 0。
- *V* 操作：当线程退出临界区时，执行 V 操作，信号量的值加 1，释放一个被阻塞的线程。



## 什么是死锁

在两个或者多个并发线程中，如果每个线程持有某种资源，而又等待其它线程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组线程产生了死锁。



## 死锁产生有哪些条件

产生死锁需要同时满足四个必要条件:

- **互斥条件**
  - 资源不能被多个进程共享
  - 如果一个资源已经被分配给了一个进程，其他进程必须等待，直到该资源被释放。
- **持有并等待**
  - 一个进程已经持有了至少一个资源,同时还在等待获取其它被占用的资源, 这个期间不会释放已经持有的资源
- **不可剥夺**
  - 已分配给进程的资源不能被强制剥夺，只有持有该资源的进程可以主动释放资源
- **循环等待**
  - 存在一个进程集合 P1,P2,...,Pn，其中 P1 等待 P2 持有的资源，P2 等待 P3 持有的资源，依此类推，直到 Pn 等待 P1 持有的资源，形成一个进程等待环。



## 如何避免死锁

打破任意一个条件即可

**消除互斥条件**

这个是没法实现，因为很多资源就是只能被一个线程占用，例如锁。

**消除请求并持有条件**

消除这个条件的办法很简单，就是一个线程一次请求其所需要的所有资源。

**消除不可剥夺条件**

占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可剥夺这个条件就破坏掉了。

**消除循环等待条件**

可以靠按序申请资源来预防。所谓按序申请，是指资源是有线性顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的，这样线性化后就不存在环路了。



## 活锁和饥饿锁了解吗

**饥饿锁**

- 这个饥饿指的是资源饥饿, 某个线程一直等不到它所需要的资源,从而无法向前推进

**活锁**

- 两个线程不断互相让步，导致没有线程能真正完成任务



# 内存管理

## 物理内存和虚拟内存有什么区别

![img](https://camo.githubusercontent.com/7c3f10416dd6c593dfb2dfadf450f2cedeee0f1d6881cf540639d4be57d2450b/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032302f776562702f313138323630372f313630353738383134313437312d31373762313962642d613637662d343564382d393562612d6166646332393263363863382e77656270)

**物理内存**指的是计算机中实际存在的硬件内存。物理内存是计算机用于存储运行中程序和数据的实际内存资源，操作系统和应用程序最终都必须使用物理内存来执行。



**虚拟内存**是操作系统提供的一种内存管理技术，它使得应用程序认为自己有连续的、独立的内存空间，而实际上，这个虚拟内存可能**部分存储在物理内存上，部分存储在磁盘（如硬盘的交换分区或页面文件）**中。



虚拟内存的核心思想是通过硬件和操作系统的配合，为每个进程提供一个独立的、完整的虚拟地址空间，解决物理内存不足的问题。

- 每个进程都有自己的虚拟地址空间，虚拟内存使用的是逻辑地址，它与实际的物理内存地址不同，必须经过地址转换才能映射到物理内存。

- 操作系统通过 **页表（Page Table）** 将虚拟地址映射到物理地址。当程序访问某个虚拟地址时，CPU 会通过页表找到对应的物理地址。

- 操作系统将虚拟内存划分为若干个**页（Pages）**，每个页可以被映射到物理内存中的一个页面。如果物理内存不够，操作系统会将不常用的页暂时存储到磁盘的交换区（Swap）中，这个过程叫做页交换（Paging）。



## 什么是内存分段

![img](https://camo.githubusercontent.com/9fbef3aca6a178556b27d14942049df6fe09d088cee696626d385e055f1a534b/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032302f776562702f313138323630372f313630353739303732323537302d34613034316532312d363561622d343835332d393561662d3661346231366133663630332e77656270)

内存分段是**操作管理虚拟地址与物理地址之间关系**的方式之一，还有一种是内存分页。

程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。**不同的段是有不同的属性的，所以就用分段的形式把这些段分离出来。**



分段的好处是能产生连续的内存空间，但是会出现内存碎片和内存交换的空间太大的问题。



## 分段为什么会产生内存碎片问题

![img](https://camo.githubusercontent.com/ed15b91fe610dbf6e6478e9b360a5641852eb9ce316c2ec4256833d40c1eba46/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032302f776562702f313138323630372f313630353739313736393531342d38623739303335652d303733352d346534662d383537392d6238623566643163336235382e77656270)



这里的内存碎片的问题共有两处地方：

- **外部内存碎片**，也就是产生了多个不连续的小物理内存，导致新的程序无法被装载；
- **内部内存碎片**，程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不是很常使用，这也会导致内存的浪费；



解决外部内存碎片的问题就是**内存交换**。

- 可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来，但是效率很低。



## 什么是内存分页

分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间就叫作页。

虚拟地址和物理地址之间通过**页表**来映射：

![img](https://camo.githubusercontent.com/cdee7180b9d5829b9968cfaf78486d15da36694d2d91740d13faa159081ea629/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032302f776562702f313138323630372f313630353739343038333534312d34653336663532352d393763302d343939302d383237612d3132353236313136653839372e77656270)



## 分页是怎么解决分段的内存碎片和内存交换效率低的问题的

![img](https://camo.githubusercontent.com/34230348a9f4faf8c720405295514f62c6214842a019bed3e1604088fc252f19/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032302f776562702f313138323630372f313630353739343830383630342d39623461366434362d373337312d346438342d613631382d6230626638333537366632322e77656270)

由于内存空间都是预先划分好的，也就不会像分段会产生间隙非常小的内存，这正是分段会产生内存碎片的原因。而**采用了分页，那么释放的内存都是以页为单位释放的，也就不会产生无法给进程使用的小内存。**

如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为**换出**（*Swap Out*）。一旦需要的时候，再加载进来，称为**换入**（*Swap In*）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，**内存交换的效率就相对比较高。**



## 分页机制下，虚拟地址和物理地址是如何映射的

在分页机制下，虚拟地址分为两部分，**页号**和**页内偏移**。页号作为页表的索引，**页表**包含物理页每页所在**物理内存的基地址**，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。

![img](https://camo.githubusercontent.com/18311a6a5836600d23e4f6652e5ce646123488a01ce731349f2c7fa63e838871/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032302f776562702f313138323630372f313630353833393130383532392d65343439663666652d346131302d343634342d393438362d6264373630393838343734322e77656270)

## 多级页表知道吗

**多级页表**（Multilevel Page Table）是一种内存管理技术，用于在虚拟内存系统中高效地管理和转换虚拟地址到物理地址。它通过分层结构减少页表所需的内存开销，以解决单级页表在大地址空间中的效率问题。

![三分恶面渣逆袭：多级页表示意图](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-3021f22f-b9a3-49d9-9e80-6d3abaf5a61a.png)

第一层存放**页目录**，每个目录项指向一个 **页表**。这样，一级页表就可以覆盖整个 4GB 虚拟地址空间，但**如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表**。



那么为什么不分级的页表就做不到这样节约内存呢？我们从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以**页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项**（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。



## 什么是快表

同样利用了`局部性原理`，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。

利用这⼀特性，把最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯片中，加入了⼀个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB（*Translation Lookaside Buffer*） ，通常称为页表缓存、转址旁路缓存、快表等。

![TLB示意图-来源参考[3]](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-cdc02a2f-59bf-45dc-8531-83b46f77bd65.png)



## 什么是交换空间

操作系统把物理内存(Physical RAM)分成一块一块的小内存，每一块内存被称为页(page)。**当内存资源不足时，Linux 把某些页的内容转移至磁盘上的一块空间上，以释放内存空间**。磁盘上的那块空间叫做交换空间(swap space)，而这一过程被称为交换(swapping)。



虚拟内存的可用容量 = 物理内存的容量 + 交换空间的容量



## 什么是缺页中断

**缺页中断**（Page Fault）是虚拟内存管理的一个重要概念。当一个程序访问的页（页面）不在物理内存中时，就会发生缺页中断。操作系统需要从磁盘上的交换区（或页面文件）中将缺失的页调入内存。



## 页面置换算法有哪些

**1. 最佳页面置换算法**

基本思路是，淘汰以后不会使用的页面。这是理论上的最佳算法，因为它可以保证最低的缺页率。但在实际应用中，由于无法预知未来的访问模式，OPT 通常无法实现。

**2. 先进先出置换算法**

基本思路是，优先淘汰最早进入内存的页面。FIFO 算法维护一个队列，新来的页面加入队尾，当发生页面置换时，队头的页面（即最早进入内存的页面）被移出。

**3. 最近最久未使用的置换算法**

淘汰最近没有使用的页面。LRU 算法根据页面的访问历史来进行置换，最长时间未被访问的页面将被置换出去。

![三分恶面渣逆袭：LRU实现](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-90810f7f-aa5b-4626-9761-c2c622b5e561.png)

**4. 时钟页面置换算法**

![三分恶面渣逆袭：时钟页面置换算法](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-3646408f-999e-48a1-84e9-113525778aca.png)

一个指针（Clock Hand） 在队列中顺时针移动，寻找可替换的页面：

- **如果当前页面的访问位是 1**：清除该访问位（设为 0），指针继续向前移动。
- **如果当前页面的访问位是 0**：表示该页面较久未使用，直接替换它。

**5. 最不常用置换算法**

根据页面被访问的频率进行置换，访问次数最少的页面最先被置换。实现较为复杂，需要记录每个页面的访问频率。



## CPU Cache是什么

![图片](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZf0RnQxwibdcyFOTw0NvInPPKJan1icpeMMyiawV2UvVwcCayaDLWJ00D3rh78LYZqBwOv9tSTYCvRog/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1)

随着时间的推移，CPU 和内存的访问性能相差越来越大，于是就在 CPU 内部嵌入了 CPU Cache（高速缓存），CPU Cache 离 CPU 核心相当近，因此它的访问速度是很快的，于是它充当了 CPU 与内存之间的缓存角色。



CPU Cache 通常分为三级缓存：L1 Cache、L2 Cache、L3 Cache，级别越低的离 CPU 核心越近，访问速度也快，但是存储容量相对就会越小。其中，在多核心的 CPU 里，每个核心都有各自的 L1/L2 Cache，而 L3 Cache 是所有核心共享使用的。



![图片](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZf0RnQxwibdcyFOTw0NvInPPqq0bdialqhibQeqDqhQEChs66jiaSS6Is6bsVChd7h8Edcr6ics7hHFSWQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1)

CPU Cache 是由很多个 Cache Line 组成的，CPU Line 是 CPU 从内存读取数据的基本单位，而 CPU Line 是由各种标志（Tag）+ 数据块（Data Block）组成。



## 写直达和写回是什么

我们当然期望 CPU 读取数据的时候，都是尽可能地从 CPU Cache 中读取，而不是每一次都要从内存中获取数据。

事实上，数据不光是只有读操作，还有写操作，那么如果数据写入 Cache 之后，内存与 Cache 相对应的数据将会不同，这种情况下 Cache 和内存数据都不一致了，于是我们肯定是要把 Cache 中的数据同步到内存里的。

**写直达**

保持内存与 Cache 一致性最简单的方式是，**把数据同时写入内存和 Cache 中**，这种方法称为**写直达（Write Through）**。

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZf0RnQxwibdcyFOTw0NvInPPxAqS638ehVB4PrVWegKibqcweFjcM7QboHV7ialgHJzjfv4NyP6ELStg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1" alt="图片" style="zoom:50%;" />

在这个方法里，写入前会先判断数据是否已经在 CPU Cache 里面了：

- 如果数据已经在 Cache 里面，先将数据更新到 Cache 里面，再写入到内存里面；
- 如果数据没有在 Cache 里面，就直接把数据更新到内存里面。

写直达法很直观，也很简单，但是问题明显，无论数据在不在 Cache 里面，每次写操作都会写回到内存，这样写操作将会花费大量的时间，无疑性能会受到很大的影响。



**写回**

既然写直达由于每次写操作都会把数据写回到内存，而导致影响性能，于是为了要减少数据写回内存的频率，就出现了**写回（Write Back）的方法**。

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZf0RnQxwibdcyFOTw0NvInPP4mia18R69AbGx4dxQfekrlm0GIpBf4TZeGlFl5uzoEvmCwo3ibfr26mA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1" alt="图片" style="zoom:50%;" />

- 如果当发生写操作时，数据已经在 CPU Cache 里的话，则把数据更新到 CPU Cache 里，同时标记 CPU Cache 里的这个 Cache Block 为脏（Dirty）的，这个脏的标记代表这个时候，我们 CPU Cache 里面的这个 Cache Block 的数据和内存是不一致的，这种情况是不用把数据写到内存里的；
- 如果当发生写操作时，数据所对应的 Cache Block 里存放的是「别的内存地址的数据」的话，就要检查这个 Cache Block 里的数据有没有被标记为脏的，如果是脏的话，我们就要把这个 Cache Block 里的数据写回到内存，然后再把当前要写入的数据，写入到这个 Cache Block 里，同时也把它标记为脏的；如果 Cache Block 里面的数据没有被标记为脏，则就直接将数据写入到这个 Cache Block 里，然后再把这个 Cache Block 标记为脏的就好了。



## 什么是缓存一致性问题

现在 CPU 都是多核的，由于 L1/L2 Cache 是多个核心各自独有的，那么会带来多核心的**缓存一致性（Cache Coherence）** 的问题，如果不能保证缓存一致性的问题，就可能造成结果错误。



<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZf0RnQxwibdcyFOTw0NvInPP0X3HRe9Z0A85WXDVBR41or8nlKew9QwCh73eh3YBIibDwCGicQ0E3M9A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1" alt="图片" style="zoom:50%;" />

这时如果 A 号核心执行了 `i++` 语句的时候，为了考虑性能，使用了我们前面所说的写回策略，先把值为 `1` 的执行结果写入到 L1/L2 Cache 中，然后把 L1/L2 Cache 中对应的 Block 标记为脏的，这个时候数据其实没有被同步到内存中的，因为写回策略，只有在 A 号核心中的这个 Cache Block 要被替换的时候，数据才会写入到内存里。

如果这时旁边的 B 号核心尝试从内存读取 i 变量的值，则读到的将会是错误的值，因为刚才 A 号核心更新 i 值还没写入到内存中，内存中的值还依然是 0。**这个就是所谓的缓存一致性问题，A 号核心和 B 号核心的缓存，在这个时候是不一致，从而会导致执行结果的错误。**



那么，要解决这一问题，就需要一种机制，来同步两个不同核心里面的缓存数据。要实现的这个机制的话，要保证做到下面这 2 点：

- 第一点，某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache，这个称为**写传播（Write Propagation）**；
- 第二点，某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为**事务的串形化（Transaction Serialization）**。



## 总线嗅探是什么

写传播的原则就是当某个 CPU 核心更新了 Cache 中的数据，要把该事件广播通知到其他核心。最常见实现的方式是**总线嗅探（Bus Snooping）**。

当 A 号 CPU 核心修改了 L1 Cache 中 i 变量的值，通过总线把这个事件广播通知给其他所有的核心，然后每个 CPU 核心都会监听总线上的广播事件，并检查是否有相同的数据在自己的 L1 Cache 里面，如果 B 号 CPU 核心的 L1 Cache 中有该数据，那么也需要把该数据更新到自己的 L1 Cache。

总线嗅探方法很简单， CPU 需要每时每刻监听总线上的一切活动，但是不管别的核心的 Cache 是否缓存相同的数据，都需要发出一个广播事件，这无疑会加重总线的负载。

另外，总线嗅探只是保证了某个 CPU 核心的 Cache 更新数据这个事件能被其他 CPU 核心知道，但是并不能保证事务串形化。



## MESI协议是什么

基于总线嗅探机制实现了事务串形化，也用状态机机制降低了总线带宽压力，这个协议就是 MESI 协议，这个协议就做到了 CPU 缓存一致性。



MESI 协议其实是 4 个状态单词的开头字母缩写，分别是：

- *Modified*，已修改
- *Exclusive*，独占
- *Shared*，共享
- *Invalidated*，已失效

「已修改」状态就是我们前面提到的脏标记，代表该 Cache Block 上的数据已经被更新过，但是还没有写到内存里。而「已失效」状态，表示的是这个 Cache Block 里的数据已经失效了，不可以读取该状态的数据。

「独占」和「共享」状态都代表 Cache Block 里的数据是干净的，也就是说，这个时候 Cache Block 里的数据和内存里面的数据是一致性的。

「独占」和「共享」的差别在于，独占状态的时候，数据只存储在一个 CPU 核心的 Cache 里，而其他 CPU 核心的 Cache 没有该数据。这个时候，如果要向独占的 Cache 写数据，就可以直接自由地写入，而不需要通知其他 CPU 核心，因为只有你这有这个数据，就不存在缓存一致性的问题了，于是就可以随便操作该数据。

另外，在「独占」状态下的数据，如果有其他核心从内存读取了相同的数据到各自的 Cache ，那么这个时候，独占状态下的数据就会变成共享状态。

那么，「共享」状态代表着相同的数据在多个 CPU 核心的 Cache 里都有，所以当我们要更新 Cache 里面的数据的时候，不能直接修改，而是要先向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为「无效」状态，然后再更新当前 Cache 里面的数据。

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZf0RnQxwibdcyFOTw0NvInPP3P2XZDHKy7EzWzfnOUugqByGVarxSnst6y78DkSmNHksLMlcd2Vlpg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1" alt="图片" style="zoom:50%;" />

我们举个具体的例子来看看这四个状态的转换：

1. 当 A 号 CPU 核心从内存读取变量 i 的值，数据被缓存在 A 号 CPU 核心自己的 Cache 里面，此时其他 CPU 核心的 Cache 没有缓存该数据，于是标记 Cache Line 状态为「独占」，此时其 Cache 中的数据与内存是一致的；
2. 然后 B 号 CPU 核心也从内存读取了变量 i 的值，此时会发送消息给其他 CPU 核心，由于 A 号 CPU 核心已经缓存了该数据，所以会把数据返回给 B 号 CPU 核心。在这个时候， A 和 B 核心缓存了相同的数据，Cache Line 的状态就会变成「共享」，并且其 Cache 中的数据与内存也是一致的；
3. 当 A 号 CPU 核心要修改 Cache 中 i 变量的值，发现数据对应的 Cache Line 的状态是共享状态，则要向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为「无效」状态，然后 A 号 CPU 核心才更新 Cache 里面的数据，同时标记 Cache Line 为「已修改」状态，此时 Cache 中的数据就与内存不一致了。
4. 如果 A 号 CPU 核心「继续」修改 Cache 中 i 变量的值，由于此时的 Cache Line 是「已修改」状态，因此不需要给其他 CPU 核心发送消息，直接更新数据即可。
5. 如果 A 号 CPU 核心的 Cache 里的 i 变量对应的  Cache Line 要被「替换」，发现  Cache Line 状态是「已修改」状态，就会在替换前先把数据同步到内存。



# 文件

## 硬链接和软链接有什么区别

![硬链接-来源参考[3]](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-d3f778f9-506b-4b93-9fb7-40eb0a79874e.png)

硬链接，以文件副本的形式存在，所有的硬链接都指向同一个iNode X，他们都享有同一个inode X和一个数据块（data block）。但硬链接本身并不占用实际存储空间。如果A文件和B文件的关系是硬链接的关系，当用户修改了A文件的内容，那么B文件的内容也会发生更改。反之一样。

删除任何一个硬链接，数据不会丢失，只有所有硬链接都删除，数据才会被真正删除





![软链接-来源参考[3]](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-81abf13c-5c60-4263-8fcb-c79c33d865e8.png)

软链接（file-软链接）本身是一个单独的文件,拥有自己的inode Y 和自己的数据块。因此拥有自己的文件属性和权限。 最大的特点是：明确自己是符号链接文件,并存放了指向源文件（file）的inode X（告知别人自己是继承谁）

软链接类似Windows中的快捷方式，为一个源文件创建一个快捷方式。如果源文件被删除了，也没有办法使用该快捷方式；一旦以同样文件名创建了源文件，链接将继续指向该文件的新数据。



软链接只是存储目标文件的路径，而不是数据本身。

访问软链接时，系统会先读取软链接指向的路径，再访问目标文件。



# IO

## 零拷贝了解吗

![传统文件传输示意图-来源参考[3]](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-1e595664-6585-4d56-8939-08b7ce510218.png)

如图所示，展示了从磁盘文件读取数据并通过网络发送文件的流程。整个流程涉及**四次数据拷贝**和**四次上下文切换**。

**四次拷贝**：

- DMA 拷贝（磁盘 → 内核缓冲区）
- CPU 拷贝（内核缓冲区 → 用户缓冲区）
- CPU 拷贝（用户缓冲区 → socket 缓冲区）
- DMA 拷贝（socket 缓冲区 → 网卡）

**四次上下文切换**：

- `read()` 触发 用户态 → 内核态
- `read()` 返回 内核态 → 用户态
- `write()` 触发 用户态 → 内核态
- `write()` 返回 内核态 → 用户态

为了提升 I/O 性能，就需要**减少用户态与内核态的上下文切换**和**内存拷贝的次数**。

零拷贝技术的实现主要有两种：

- mmap + write：减少了一次内核态到用户态的拷贝

  ![mmap示意图-来源参考[3]](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-6dc49f9d-0bc3-4956-a650-7c7236f234a2.png)

  DMA 拷贝（磁盘 → 内核缓冲区）

  用户进程通过 `mmap` 访问数据（零拷贝，无 CPU 拷贝）

  CPU 拷贝（共享缓冲区 → socket 缓冲区）

  DMA 拷贝（socket 缓冲区 → 网卡）

  

- sendfile![sendfile示意图-来源参考[3]](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-0b087b8a-8d51-4aad-898d-d99c38d36592.png)

  它可以替代前面的 read() 和 write() 这两个系统调用，这样就可以减少⼀次系统调用，也就减少了 2 次上下文切换的开销。

  其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。



很多开源项目如 Kafka、RocketMQ 都采用了零拷贝技术来提升 IO 效率。

Kafka是sendfile，RocketMQ是mmap



## 聊聊非阻塞IO、同步、异步IO

**1. 阻塞I/O**

![阻塞I/O](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-f06db5ff-661c-4ddf-9115-4ed9c9a21d01.png)

- 用户程序执行 read ，线程会被阻塞，一直等到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序的缓冲区中，当拷贝过程完成， read 才会返回。

- 阻塞等待的是**内核数据准备好**和**数据从内核态拷贝到用户态**这两个过程。



**2. 非阻塞I/O**

![非阻塞I/O](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-771e014e-7ed9-4101-8bb5-4413b8069fd6.png)

- 非阻塞的 read 请求在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲区， read 调用才可以获取到结果。



**3. 基于非阻塞的I/O多路复用**

![基于非阻塞的I/O多路复用](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-86e54fa3-ad36-43c7-9d2d-5a68139c310f.png)

- 当内核数据准备好时，才以事件通知应用程序进行操作。

**注意：**无论是阻塞 I/O、还是非阻塞 I/O、非阻塞 I/O 多路复用，都是同步调用。因为它们在 read 调用时，内核将数据从内核空间拷贝到应用程序空间，过程都是需要等待的，也就是说这个过程是**同步**的，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间。



**4. 异步I/O**

![异步/IO](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-869021ed-5e4e-4490-9174-7291d8ddf55c.png)

- 真正的异步I/O是**内核数据准备好**和**数据从内核态拷贝到用户态**这两个过程都不用等待。

- 发起 aio_read 之后，就立即返回，内核自动将数据从内核空间拷贝到应用程序空间，这个拷贝过程同样是异步的，内核自动完成的，和前面的同步操作不⼀样，应用程序并不需要主动发起拷贝动作。



## 详细讲一讲IO多路复用

在传统的 I/O 模型中，如果服务端需要支持多个客户端，可能要为每个客户端分配一个进程/线程。

不管是基于重一点的进程模型，还是轻一点的线程模型，假如连接多了，操作系统是扛不住的。

所以就引入了**I/O 多路复用** 技术。

简单说，就是**一个进程/线程维护多个 Socket**，这个多路复用就是多个连接复用一个进程/线程。

![I/O多路复用](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-9b276b14-eb1b-47bf-b2aa-25212e1bbdf8.png)

**select**

- 将已连接的 Socket 都放到⼀个**文件描述符集合**fd_set，然后调用 select 函数将 fd_set 集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历 fd_set 的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个 fd_set 拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，再对其处理。

- select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024 ，只能监听 0~1023 的文件描述符。



**poll**

- poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。

- 但是 poll 和 select 并没有太大的本质区别，都是使用线性结构存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。



**epoll**

- ![epoll接口作用-来源参考[3]](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/sidebar/sanfene/os-cca76ac4-cfb4-4374-8fc6-256cd4d3893f.png)
- epoll 在内核里使用**红黑树来跟踪进程所有待检测的文件描述字**，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里

- epoll 使用事件驱动的机制，内核里**维护了⼀个链表来记录就绪事件**，当某个 socket 有事件发生时，通过回调函数，内核会将其加入到这个就绪事件列表中，当用户调用epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。



## 普通内存比一般的机械硬盘快多少

![图片来源于网络](https://cdn.tobebetterjavaer.com/stutymore/os-20240410101801.png)

**机械硬盘**，也叫 HDD（Hard Disk Drive），是一种通过磁盘旋转和磁头移动来存储数据的设备，读写速度比较慢。

- HDD 的访问时间大约在 5-10ms，数据传输速率约为 100 到 200 MB/s。
- 内存，也就是 RAM（Random Access Memory），访问时间大约在 10-100ns，数据传输速率约为数十 GB/s。

**固态硬盘**（Solid State Drive，SSD），SSD 的读写速度比 HDD 快 200 倍左右，价格也在逐渐下降，已经逐渐取代了 HDD。

